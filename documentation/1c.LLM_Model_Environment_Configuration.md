# Environment configuration

The `.env` file is used to contain the parameters needed to call an LLM. 

Multiple LLM parameters can be stored in the `.env` file at once; this will allow users to initiate multiple tests at once. Each LLM that runs is considered a separate test run.

The basic structure for configuring an LLM within the `.env` file is as follows. This would be considered a LLM Parameter Block:
```
ID=[MODEL_NAME].upper() + [LAST_4_DIGITS_API-KEY].upper()
PLATFORM=[HOSTING_PLATFORM_NAME]
API-KEY=[API_KEY]
MODEL=[MODEL_NAME]
TEMPERATURE=[FLOAT_BETWEEN_0_AND_1]
```

Example LLM Parameter Block:
```
ID=GPT-4-21AB
PLATFORM=OPENAI
API-KEY=0987654321ab
MODEL=gpt-4
TEMPERATURE=0.7
```

### Important Notes

- When adding multiple LLMs to the `.env` file, there must be a newline separating LLM Parameter Blocks
- There should not be any spaces within a parameter block
- If locally hosting, `PLATFORM` should equal `LOCAL`
- `MODEL_NAME`, if for a hosted platform, should match the formatting and content of the name required within the API call.
  - e.g. togehterAI's LLama 70b --> togethercomputer/llama-2-70b-chat
- You can use the [guided model configuration](./../README.md) within the LLM Canary tool for both [pre-defined models](./3.Platforms_and_Models.md) and custom/locally hosted ones. This will automatically format the LLM Parameter Blocks
  - you can configure multiple LLM Parameter Blocks at once usign the guided model configuration
  - Alternatively, you can edit the .env file directly

---

### Next Steps

- [Checking Model Configuration](./1d.Checking_Model_Configuration.md)
- [Return To The Quick Start Guide](./1.Quick_Start_Guide.md)