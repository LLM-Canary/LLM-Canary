# Platforms and Models

The LLM-Canary tool works on a per-platform basis, meaning that if a hosted platform is configured, all models on that platform can be run against the tool. 

Available platforms can be configured in `to_customize/model_calls`.

Pre-configured platforms include:
 - OpenAI
 - TogetherAI

The guided model configuration within the tool lists some pre-configured models to choose from.
- OpenAI
  - gpt-3.5-turbo
  - gpt-3.5-turbo-16k-0613
  - gpt-4
  - gpt-4-0314
- TogetherAI
  - togethercomputer/llama-2-70b-chat
  - huggyllama/llama-7b
  - NousResearch/Nous-Hermes-13b
  - EleutherAI/pythia-12b-v0
  - lmsys/vicuna-7b-v1.5
  - databricks/dolly-v2-7b
 
This list is not extensive. If a model exists on one of these hosted platforms and is not listed, it can still be configured without having to add [custom model_calls](./1a.Adding_New_LLMs.md).

Other hosted platforms and locally hosted models can be added by following the [adding new LLMs/Platforms](./1a.Adding_New_LLMs.md) steps.

---

### Next Steps

- [Quick Start Guide](./1.Quick_Start_Guide.md)